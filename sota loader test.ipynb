{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28276f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 11:28:58.771320: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /mnt/e/MAF_API/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-12-01 11:28:58.771354: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained on [[[  cpu  ]]] device.\n",
      "Trained on [[[  cpu  ]]] device.\n",
      "Train on [[[  cpu  ]]] device.\n",
      "Train on [[[  cpu  ]]] device.\n",
      "Train on [[[  cpu  ]]] device.\n"
     ]
    }
   ],
   "source": [
    "from Kaif.Algorithms.sota import FairBatch, FairFeatureDistillation, FairnessVAE, KernelDensityEstimator, LearningFromFairness\n",
    "from Kaif.Metric import ClassificationMetric\n",
    "from Kaif.DataSet import RawDataSet\n",
    "\n",
    "from sample import AdultDataset, GermanDataset, PubFigDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdf64f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "pubfig = PubFigDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1adfda17",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pubfig.to_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "63640bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make privileged group and unprivileged group\n",
    "privilege = [{key: value[0]} for key, value in zip(dataset['aif_dataset'].protected_attribute_names, dataset['aif_dataset'].privileged_protected_attributes)]\n",
    "unprivilege = [{key: value[0]} for key, value in zip(dataset['aif_dataset'].protected_attribute_names, dataset['aif_dataset'].unprivileged_protected_attributes)]\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Flatten the images and convert numpy\n",
    "fltn_img = np.array([img.ravel() for img in dataset['image_list']], dtype='int')\n",
    "\n",
    "# Split the dataset\n",
    "train_img, test_img, train_target, test_target, train_bias, test_bias = train_test_split(fltn_img, dataset['target'], dataset['bias'], train_size=0.7, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fa6babdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train teacher start\n",
      "Epoch [1/20], Batch [0/35], Loss 0.7240089774131775\n",
      "Epoch [1/20], Batch [10/35], Loss 0.8165768384933472\n",
      "Epoch [1/20], Batch [20/35], Loss 0.7046980261802673\n",
      "Epoch [1/20], Batch [30/35], Loss 0.6610365509986877\n",
      "Epoch [2/20], Batch [0/35], Loss 0.649886965751648\n",
      "Epoch [2/20], Batch [10/35], Loss 0.7583650350570679\n",
      "Epoch [2/20], Batch [20/35], Loss 0.6473614573478699\n",
      "Epoch [2/20], Batch [30/35], Loss 0.6765059232711792\n",
      "Epoch [3/20], Batch [0/35], Loss 0.8173194527626038\n",
      "Epoch [3/20], Batch [10/35], Loss 0.5341435670852661\n",
      "Epoch [3/20], Batch [20/35], Loss 0.5895872712135315\n",
      "Epoch [3/20], Batch [30/35], Loss 0.6106736660003662\n",
      "Epoch [4/20], Batch [0/35], Loss 0.4995141923427582\n",
      "Epoch [4/20], Batch [10/35], Loss 0.6285754442214966\n",
      "Epoch [4/20], Batch [20/35], Loss 0.5878218412399292\n",
      "Epoch [4/20], Batch [30/35], Loss 0.5327085256576538\n",
      "Epoch [5/20], Batch [0/35], Loss 0.5292989015579224\n",
      "Epoch [5/20], Batch [10/35], Loss 0.674863338470459\n",
      "Epoch [5/20], Batch [20/35], Loss 0.5499980449676514\n",
      "Epoch [5/20], Batch [30/35], Loss 0.7860211133956909\n",
      "Epoch [6/20], Batch [0/35], Loss 0.5283591151237488\n",
      "Epoch [6/20], Batch [10/35], Loss 0.45083871483802795\n",
      "Epoch [6/20], Batch [20/35], Loss 0.5444560050964355\n",
      "Epoch [6/20], Batch [30/35], Loss 0.5856984853744507\n",
      "Epoch [7/20], Batch [0/35], Loss 0.486420601606369\n",
      "Epoch [7/20], Batch [10/35], Loss 0.47766271233558655\n",
      "Epoch [7/20], Batch [20/35], Loss 0.43384164571762085\n",
      "Epoch [7/20], Batch [30/35], Loss 0.5164406299591064\n",
      "Epoch [8/20], Batch [0/35], Loss 0.43003547191619873\n",
      "Epoch [8/20], Batch [10/35], Loss 0.32118454575538635\n",
      "Epoch [8/20], Batch [20/35], Loss 0.5294052958488464\n",
      "Epoch [8/20], Batch [30/35], Loss 0.4374474883079529\n",
      "Epoch [9/20], Batch [0/35], Loss 0.41077330708503723\n",
      "Epoch [9/20], Batch [10/35], Loss 0.3224540650844574\n",
      "Epoch [9/20], Batch [20/35], Loss 0.438874214887619\n",
      "Epoch [9/20], Batch [30/35], Loss 0.47295671701431274\n",
      "Epoch [10/20], Batch [0/35], Loss 0.28236132860183716\n",
      "Epoch [10/20], Batch [10/35], Loss 0.1867058277130127\n",
      "Epoch [10/20], Batch [20/35], Loss 0.48407426476478577\n",
      "Epoch [10/20], Batch [30/35], Loss 0.4761417806148529\n",
      "Epoch [11/20], Batch [0/35], Loss 0.4034453332424164\n",
      "Epoch [11/20], Batch [10/35], Loss 0.33461272716522217\n",
      "Epoch [11/20], Batch [20/35], Loss 0.4686688482761383\n",
      "Epoch [11/20], Batch [30/35], Loss 0.5036869049072266\n",
      "Epoch [12/20], Batch [0/35], Loss 0.3565097749233246\n",
      "Epoch [12/20], Batch [10/35], Loss 0.15027542412281036\n",
      "Epoch [12/20], Batch [20/35], Loss 0.524778425693512\n",
      "Epoch [12/20], Batch [30/35], Loss 0.389178067445755\n",
      "Epoch [13/20], Batch [0/35], Loss 0.35172536969184875\n",
      "Epoch [13/20], Batch [10/35], Loss 0.2544669806957245\n",
      "Epoch [13/20], Batch [20/35], Loss 0.26133641600608826\n",
      "Epoch [13/20], Batch [30/35], Loss 0.4519157409667969\n",
      "Epoch [14/20], Batch [0/35], Loss 0.20718808472156525\n",
      "Epoch [14/20], Batch [10/35], Loss 0.18222230672836304\n",
      "Epoch [14/20], Batch [20/35], Loss 0.3968666195869446\n",
      "Epoch [14/20], Batch [30/35], Loss 0.5523927211761475\n",
      "Epoch [15/20], Batch [0/35], Loss 0.1898680329322815\n",
      "Epoch [15/20], Batch [10/35], Loss 0.2746765911579132\n",
      "Epoch [15/20], Batch [20/35], Loss 0.2099766880273819\n",
      "Epoch [15/20], Batch [30/35], Loss 0.40059351921081543\n",
      "Epoch [16/20], Batch [0/35], Loss 0.13608033955097198\n",
      "Epoch [16/20], Batch [10/35], Loss 0.2518618702888489\n",
      "Epoch [16/20], Batch [20/35], Loss 0.1984601616859436\n",
      "Epoch [16/20], Batch [30/35], Loss 0.17283739149570465\n",
      "Epoch [17/20], Batch [0/35], Loss 0.1349509358406067\n",
      "Epoch [17/20], Batch [10/35], Loss 0.06663103401660919\n",
      "Epoch [17/20], Batch [20/35], Loss 0.20920969545841217\n",
      "Epoch [17/20], Batch [30/35], Loss 0.1375502347946167\n",
      "Epoch [18/20], Batch [0/35], Loss 0.19200119376182556\n",
      "Epoch [18/20], Batch [10/35], Loss 0.13376712799072266\n",
      "Epoch [18/20], Batch [20/35], Loss 0.1751774549484253\n",
      "Epoch [18/20], Batch [30/35], Loss 0.14796802401542664\n",
      "Epoch [19/20], Batch [0/35], Loss 0.07856031507253647\n",
      "Epoch [19/20], Batch [10/35], Loss 0.19159430265426636\n",
      "Epoch [19/20], Batch [20/35], Loss 0.14359208941459656\n",
      "Epoch [19/20], Batch [30/35], Loss 0.1289231777191162\n",
      "Epoch [20/20], Batch [0/35], Loss 0.04628739878535271\n",
      "Epoch [20/20], Batch [10/35], Loss 0.11440973728895187\n",
      "Epoch [20/20], Batch [20/35], Loss 0.026765020564198494\n",
      "Epoch [20/20], Batch [30/35], Loss 0.24118945002555847\n",
      "Train teacher done.\n",
      "Train student start\n",
      "Epoch [1/20], Batch [0/35], Loss 13.713918685913086\n",
      "Epoch [1/20], Batch [10/35], Loss 11.371545791625977\n",
      "Epoch [1/20], Batch [20/35], Loss 13.364849090576172\n",
      "Epoch [1/20], Batch [30/35], Loss 10.863449096679688\n",
      "Epoch [2/20], Batch [0/35], Loss 9.855096817016602\n",
      "Epoch [2/20], Batch [10/35], Loss 9.864768981933594\n",
      "Epoch [2/20], Batch [20/35], Loss 9.195103645324707\n",
      "Epoch [2/20], Batch [30/35], Loss 11.182924270629883\n",
      "Epoch [3/20], Batch [0/35], Loss 10.037741661071777\n",
      "Epoch [3/20], Batch [10/35], Loss 9.000954627990723\n",
      "Epoch [3/20], Batch [20/35], Loss 9.14208698272705\n",
      "Epoch [3/20], Batch [30/35], Loss 11.802322387695312\n",
      "Epoch [4/20], Batch [0/35], Loss 8.009557723999023\n",
      "Epoch [4/20], Batch [10/35], Loss 8.440163612365723\n",
      "Epoch [4/20], Batch [20/35], Loss 9.940940856933594\n",
      "Epoch [4/20], Batch [30/35], Loss 9.975841522216797\n",
      "Epoch [5/20], Batch [0/35], Loss 7.791922569274902\n",
      "Epoch [5/20], Batch [10/35], Loss 8.540305137634277\n",
      "Epoch [5/20], Batch [20/35], Loss 6.541934490203857\n",
      "Epoch [5/20], Batch [30/35], Loss 11.210022926330566\n",
      "Epoch [6/20], Batch [0/35], Loss 7.143060684204102\n",
      "Epoch [6/20], Batch [10/35], Loss 7.206177711486816\n",
      "Epoch [6/20], Batch [20/35], Loss 7.561901569366455\n",
      "Epoch [6/20], Batch [30/35], Loss 7.635704517364502\n",
      "Epoch [7/20], Batch [0/35], Loss 7.100115776062012\n",
      "Epoch [7/20], Batch [10/35], Loss 5.755670547485352\n",
      "Epoch [7/20], Batch [20/35], Loss 6.857299327850342\n",
      "Epoch [7/20], Batch [30/35], Loss 8.017087936401367\n",
      "Epoch [8/20], Batch [0/35], Loss 4.836463451385498\n",
      "Epoch [8/20], Batch [10/35], Loss 4.075013637542725\n",
      "Epoch [8/20], Batch [20/35], Loss 7.0260162353515625\n",
      "Epoch [8/20], Batch [30/35], Loss 6.731575012207031\n",
      "Epoch [9/20], Batch [0/35], Loss 5.426114082336426\n",
      "Epoch [9/20], Batch [10/35], Loss 9.836584091186523\n",
      "Epoch [9/20], Batch [20/35], Loss 7.268521785736084\n",
      "Epoch [9/20], Batch [30/35], Loss 4.81551456451416\n",
      "Epoch [10/20], Batch [0/35], Loss 4.468048572540283\n",
      "Epoch [10/20], Batch [10/35], Loss 4.869544982910156\n",
      "Epoch [10/20], Batch [20/35], Loss 3.7362961769104004\n",
      "Epoch [10/20], Batch [30/35], Loss 7.7298383712768555\n",
      "Epoch [11/20], Batch [0/35], Loss 3.8487112522125244\n",
      "Epoch [11/20], Batch [10/35], Loss 4.713815689086914\n",
      "Epoch [11/20], Batch [20/35], Loss 5.200629234313965\n",
      "Epoch [11/20], Batch [30/35], Loss 4.451577663421631\n",
      "Epoch [12/20], Batch [0/35], Loss 3.8436548709869385\n",
      "Epoch [12/20], Batch [10/35], Loss 4.12005615234375\n",
      "Epoch [12/20], Batch [20/35], Loss 4.765613079071045\n",
      "Epoch [12/20], Batch [30/35], Loss 2.759406805038452\n",
      "Epoch [13/20], Batch [0/35], Loss 2.9393858909606934\n",
      "Epoch [13/20], Batch [10/35], Loss 3.189054250717163\n",
      "Epoch [13/20], Batch [20/35], Loss 4.46013069152832\n",
      "Epoch [13/20], Batch [30/35], Loss 3.9244585037231445\n",
      "Epoch [14/20], Batch [0/35], Loss 3.2830612659454346\n",
      "Epoch [14/20], Batch [10/35], Loss 3.9421849250793457\n",
      "Epoch [14/20], Batch [20/35], Loss 3.806950330734253\n",
      "Epoch [14/20], Batch [30/35], Loss 3.6315128803253174\n",
      "Epoch [15/20], Batch [0/35], Loss 3.4682910442352295\n",
      "Epoch [15/20], Batch [10/35], Loss 2.7149226665496826\n",
      "Epoch [15/20], Batch [20/35], Loss 4.007133960723877\n",
      "Epoch [15/20], Batch [30/35], Loss 4.532186508178711\n",
      "Epoch [16/20], Batch [0/35], Loss 1.8562761545181274\n",
      "Epoch [16/20], Batch [10/35], Loss 2.6446001529693604\n",
      "Epoch [16/20], Batch [20/35], Loss 3.811192750930786\n",
      "Epoch [16/20], Batch [30/35], Loss 3.155017614364624\n",
      "Epoch [17/20], Batch [0/35], Loss 2.546185255050659\n",
      "Epoch [17/20], Batch [10/35], Loss 2.7066853046417236\n",
      "Epoch [17/20], Batch [20/35], Loss 1.8632371425628662\n",
      "Epoch [17/20], Batch [30/35], Loss 1.6734412908554077\n",
      "Epoch [18/20], Batch [0/35], Loss 1.7566438913345337\n",
      "Epoch [18/20], Batch [10/35], Loss 2.0729997158050537\n",
      "Epoch [18/20], Batch [20/35], Loss 2.298147678375244\n",
      "Epoch [18/20], Batch [30/35], Loss 2.5044941902160645\n",
      "Epoch [19/20], Batch [0/35], Loss 1.6845602989196777\n",
      "Epoch [19/20], Batch [10/35], Loss 1.4927643537521362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Batch [20/35], Loss 2.024418354034424\n",
      "Epoch [19/20], Batch [30/35], Loss 2.1895289421081543\n",
      "Epoch [20/20], Batch [0/35], Loss 1.4865399599075317\n",
      "Epoch [20/20], Batch [10/35], Loss 2.039121150970459\n",
      "Epoch [20/20], Batch [20/35], Loss 2.4059457778930664\n",
      "Epoch [20/20], Batch [30/35], Loss 2.1663427352905273\n",
      "Train student end.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "evaluation() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [77]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m ffd\u001b[38;5;241m.\u001b[39mtrain_student()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Prediction\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mffd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_shape\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: evaluation() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "# Fair feature distillation (Image only)\n",
    "#protected_label = dataset_train.protected_attribute_names[0]\n",
    "#protected_idx = dataset_train.feature_names.index(protected_label)\n",
    "#biased = dataset_train.features[:, protected_idx]\n",
    "\n",
    "# RawDataSet\n",
    "train_data = RawDataSet(x=train_img, y=train_target, z=train_bias)\n",
    "test_data = RawDataSet(x=test_img, y=test_target, z=test_bias)\n",
    "\n",
    "# Train\n",
    "n_epoch = 20\n",
    "batch_size = 64\n",
    "learning_rate = 0.01\n",
    "image_shape = (3, 64, 64)\n",
    "ffd = FairFeatureDistillation.FFD(train_data, n_epoch, batch_size, learning_rate, image_shape)\n",
    "ffd.train_teacher()\n",
    "ffd.train_student()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "118cd26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation finished.\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "pred = ffd.evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dbfacd83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dedb3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
